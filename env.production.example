# Production Environment Configuration

# Server
PORT=3000
NODE_ENV=production

# LLM Provider Configuration
DEFAULT_LLM_PROVIDER=openai

# Provider Settings
OPENAI_API_KEY=your-api-key-here
OPENAI_MODEL=mistral-nemo
OPENAI_TEMPERATURE=0
OPENAI_BASE_URL=vllm_base_url

# Processing Configuration
CHUNK_SIZE=1500
CHUNK_OVERLAP=0
ENABLE_PARALLEL_CHUNKS=true
