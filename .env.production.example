# Production Environment Configuration

# Server
PORT=3000
NODE_ENV=production

# LLM Provider Configuration
DEFAULT_LLM_PROVIDER=openai

# Provider Settings
OPENAI_API_KEY=your-api-key-here
OPENAI_MODEL=mistral-nemo
OPENAI_TEMPERATURE=0
OPENAI_BASE_URL=https://api.vllm.baseUrl/v1

# Processing Configuration
CHUNK_SIZE=1500
CHUNK_OVERLAP=0
ENABLE_PARALLEL_CHUNKS=true